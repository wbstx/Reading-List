# Attention in CV
Attention mechanism can better help the network to focus on interested areas. Itâ€™s can be applied to one image for saliency parts, or two images for their correspondences.

# Self-Attention
**(ECCV 2018)** [CBAM: Convolutional Block Attention Module][1] an attention module containing spatial attention and channel attention.

## Correlation Filter
**(CVPR 2018)** [High Performance Visual Tracking with Siamese Region Proposal Network][2]

[1]:	https://arxiv.org/abs/1807.06521
[2]:	http://www.zhengzhu.net/upload/P6938bc861e8d4583bf47d47d64ed9598.pdf