# Attention in CV
Attention mechanism can better help the network to focus on interested areas. Itâ€™s can be applied to one image for saliency parts, or two images for their correspondences.

# Self-Attention
**(ECCV 2018)** [CBAM: Convolutional Block Attention Module][1] an attention module containing spatial attention and channel attention.

**(ICCV 2019)** [GCNet: Non-local Networks Meet Squeeze-Excitation Networks and Beyond][2] A light-weight non-local block for self-attention.

## Correlation Filter
**(CVPR 2018)** [High Performance Visual Tracking with Siamese Region Proposal Network][3]

[1]:	https://arxiv.org/abs/1807.06521
[2]:	https://arxiv.org/abs/1904.11492
[3]:	http://www.zhengzhu.net/upload/P6938bc861e8d4583bf47d47d64ed9598.pdf